{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XduEam0dl1gO"
      },
      "source": [
        "## Introduction to deep learning for medical imaging\n",
        "\n",
        "### Tutorial 1. Classification of TB (Tuberculosis)  vs. NOT-TB (Not - Tuberculosis) in X-rays \n",
        "\n",
        "This is an introduction into practical deep learning application for medical image classification. The goal of this tutorial is to build a deep learning classifier to accurately differentiate between TB and NOT-TB X-rays. \n",
        "\n",
        "- Data is acquired from: https://lhncbc.nlm.nih.gov/LHC-publications/pubs/TuberculosisChestXrayImageDataSets.html.\n",
        "\n",
        "In this tutorial we download the two datasets from the above provided link and train a classifier based on montgomery dataset and check the generalization of the model on Shenzen dataset. Documentation for approach to download the datasets and setting up the folders is given under  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtIbwNKjl1gY"
      },
      "source": [
        "**Clink the badge above to launch this notebook on Google Colab.**\n",
        "To use GPU, go to Edit -> Notebook settings -> Hardware accelerator (GPU)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_l22MRm1l1gY"
      },
      "source": [
        "### Install all the required frameworks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0oAZF8PBl1gZ"
      },
      "outputs": [],
      "source": [
        "!pip install pandas\n",
        "!pip install tensorflow \n",
        "!pip install SimpleITK\n",
        "!pip install scikit-learn\n",
        "!pip install pydicom\n",
        "!pip install segmentation_models\n",
        "!pip install scikit-image"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import all the required framework for the analysis"
      ],
      "metadata": {
        "id": "M9yKh_lkIwGm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pydicom\n",
        "import zipfile\n",
        "import SimpleITK as sitk\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from skimage import exposure\n",
        "import segmentation_models as sm\n",
        "sm.set_framework('tf.keras')\n",
        "sm.framework()\n",
        "import multiprocessing\n",
        "from functools import partial\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "tJ4cgnZ-JYEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mount your Google drive and set up the root directory. "
      ],
      "metadata": {
        "id": "7wcMazPwQBNo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6BXgl35l1gf"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import requests\n",
        "\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "# Set up the root directory\n",
        "root_dir = '/content/drive/MyDrive/niehs_tutorials'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download the datasets (User can follow either of the options ).\n",
        "\n",
        "####Option 1:\n",
        "Manually download the datasets(.zip files) by opening the provided link in the Introduction and click on the 'Download link' option.  After unzipping them in your local computer, you can upload the two directories('MontgomerySet' and 'ChinaSet_AllFiles') in the root directory(In this case, root_dir = '/content/drive/MyDrive/niehs_tutorials'). If user is facing any problem in downloading the datasets, they can right click on the 'Download link' option and copy the link address to paste in a new tab of your browser. \n",
        "\n",
        "####Option 2:\n",
        "Run the below cell. Below pythonic code will download the datasets and unzips the folders under the root directory. This code snippet would take much more time to setup than option 1."
      ],
      "metadata": {
        "id": "R_RU4z3zRIDL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "montgomery_county_dataset_download_url = 'http://openi.nlm.nih.gov/imgs/collections/NLM-MontgomeryCXRSet.zip'\n",
        "shenzen_county_dataset_download_url = 'http://openi.nlm.nih.gov/imgs/collections/ChinaSet_AllFiles.zip'\n",
        "\n",
        "r1 = requests.get(montgomery_county_dataset_download_url, allow_redirects=True)\n",
        "open(os.path.join(root_dir,'montgomerycounty_data.zip'), 'wb+').write(r1.content)\n",
        "\n",
        "r2 = requests.get(montgomery_county_dataset_download_url, allow_redirects=True)\n",
        "open(os.path.join(root_dir,'shenzen_data.zip'), 'wb+').write(r2.content)\n",
        "\n",
        "\n",
        "## Unzip the files\n",
        "with zipfile.ZipFile(os.path.join(root_dir,'montgomerycounty_data.zip'), 'r') as zip_ref:\n",
        "    zip_ref.extractall(root_dir)\n",
        "with zipfile.ZipFile(os.path.join(root_dir,'shenzen_data.zip'), 'r') as zip_ref:\n",
        "    zip_ref.extractall(root_dir)\n",
        "\n",
        "## Remove the zip files as we don't need them anymore\n",
        "os.remove(os.path.join(root_dir,'montgomerycounty_data.zip'))\n",
        "os.remove(os.path.join(root_dir,'shenzen_data.zip'))"
      ],
      "metadata": {
        "id": "1hhHelk3RFCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVL36NdSl1ge"
      },
      "source": [
        "### Grab the CXRs and labels\n",
        "\n",
        "In this analysis we use shenzen dataset for model development . Label '0' indicates that the patient is not infected with tuberculosis and Label '1' indicates that patient is infected with tuberculosis"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shenzen_cxrs = glob.glob(os.path.join(root_dir,'ChinaSet_AllFiles','CXR_png','*.png'))\n",
        "shenzen_tb_cxrs = glob.glob(os.path.join(root_dir,'ChinaSet_AllFiles','CXR_png','*_1.png'))\n",
        "shenzen_not_tb_cxrs = glob.glob(os.path.join(root_dir,'ChinaSet_AllFiles','CXR_png','*_0.png'))\n",
        "shenzen_labels = [int(os.path.splitext(cxr_file)[0].split('_')[-1]) for cxr_file in shenzen_cxrs]"
      ],
      "metadata": {
        "id": "aatN8qZ5Antw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Display few random images of varying sizes"
      ],
      "metadata": {
        "id": "L7qzVojabL7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_SAMPLES = 21\n",
        "fig_rows = 3\n",
        "fig_columns = 7\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"]=10,10\n",
        "_,subfigs = plt.subplots(fig_rows, fig_columns)\n",
        "k = 0\n",
        "for row in range(fig_rows):\n",
        "  for column in range(fig_columns):\n",
        "      img = sitk.ReadImage(shenzen_cxrs[k])\n",
        "      arr = sitk.GetArrayFromImage(img)       \n",
        "      subfigs[row,column].imshow(arr, cmap = 'gray')\n",
        "      subfigs[row,column].set_title('#'+str(k))\n",
        "      subfigs[row,column].axis('off')\n",
        "      k = k+1\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TjPuICohbKGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sET3cCwl1gg"
      },
      "source": [
        "### Preprocess the CXRs\n",
        "\n",
        "In this step, we use a lung segmentation model, to detect the lung regions in the CXRs and crop the bounding box of the CXR around the lungs. In this analysis, we will use a pretrained lung segmentation model, trained on nearly 6000 covid containing patient CXRs. Dataset to train for this model has been acquired from https://github.com/v7labs/covid-19-xray-dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resample all input images to (256,256) before feeding to lung segmentation model"
      ],
      "metadata": {
        "id": "Dw_WRXKQfixp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _srgb2gray(image):\n",
        "    # Convert sRGB image to gray scale and rescale results to [0,255]    \n",
        "    channels = [sitk.VectorIndexSelectionCast(image,i, sitk.sitkFloat32) for i in range(image.GetNumberOfComponentsPerPixel())]\n",
        "    #linear mapping\n",
        "    I = 1/255.0*(0.2126*channels[0] + 0.7152*channels[1] + 0.0722*channels[2])\n",
        "    #nonlinear gamma correction\n",
        "    I = I*sitk.Cast(I<=0.0031308,sitk.sitkFloat32)*12.92 + I**(1/2.4)*sitk.Cast(I>0.0031308,sitk.sitkFloat32)*1.055-0.55\n",
        "    return sitk.Cast(sitk.RescaleIntensity(I), sitk.sitkUInt8)\n",
        "\n",
        "\n",
        "def _resample_cxr_for_lung_segmentation_cnn(new_size, gaussian_sigma, file):\n",
        "    \"\"\"\n",
        "    Downsample the input image to the given new_size. To avoid aliasing artifacts\n",
        "    you may want to blur the image before the downsampling operation. This is important\n",
        "    if your image contains high frequency data.\n",
        "    Args:\n",
        "        new_size: The size of the resampled image in pixels.\n",
        "        gaussian_sigma(scalar or tuple with image dimension length): If given,\n",
        "               blur the image with a Gaussian with the given standard deviation(s)\n",
        "               before resampling.\n",
        "        file (str): File path to image we want to resample.\n",
        "    Returns:\n",
        "        Tuple (SimpleITK.Image, SimpleITK.Image): Original image and it's normalized resampled image.\n",
        "        \"\"\"\n",
        "    print(\"Resampling ...\" + file + \" to lung segmentation model input size\")\n",
        "    original_image = sitk.ReadImage(file)\n",
        "\n",
        "    # Some images are grayscale but the channel is repeated three times (gray RGB image).\n",
        "    if original_image.GetNumberOfComponentsPerPixel() > 1:\n",
        "        original_image = _srgb2gray(original_image)\n",
        "    new_spacing = [sz * spc / nsz for nsz, sz, spc in\n",
        "                   zip(new_size, original_image.GetSize(), original_image.GetSpacing())]\n",
        "    smoothed_image = sitk.SmoothingRecursiveGaussian(original_image, gaussian_sigma)\n",
        "    resampled_for_seg = sitk.Resample(smoothed_image, new_size, sitk.Transform(), sitk.sitkLinear,\n",
        "                                      original_image.GetOrigin(), new_spacing, original_image.GetDirection(),\n",
        "                                      0, sitk.sitkFloat32)\n",
        "    return original_image, resampled_for_seg"
      ],
      "metadata": {
        "id": "oomJZ9UaegKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the lung segmentation model and predict the lung masks on the resampled images."
      ],
      "metadata": {
        "id": "8FFpE82OgtPN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_seg_model(path):\n",
        "    model = sm.Unet('resnet50',  encoder_freeze=True)\n",
        "    model.compile(optimizer='Adam',\n",
        "                 loss=sm.losses.bce_jaccard_loss,\n",
        "                 metrics=[sm.metrics.iou_score])\n",
        "    model.load_weights(path)\n",
        "    return model\n",
        "\n",
        "def _predict_mask(resampled_image_arr, model_path, batch_size=10):\n",
        "    \"\"\"\n",
        "    Predict the lung mask from the resampled image array. This uses UNet\n",
        "    (pretrained model: https://github.com/imlab-uiip/lung-segmentation-2d) to segment\n",
        "    lungs for a given image with size equal to model input size.\n",
        "\n",
        "    Args:\n",
        "        resampled_image_arr (numpy array): Numpy array obtained from resampled images\n",
        "                                           to provide input for segmentation network in the\n",
        "                                           shape of (num_images,segmentation_input_size_x,\n",
        "                                           segmentation_input_size_y)\n",
        "        model_path: File path of the trained model(UNet)\n",
        "        batch_size: Batch size for the model. Performing inference in batch mode is faster than\n",
        "                    image by image.\n",
        "    Returns:\n",
        "        Numpy array: Prediction masks of segmented lungs with same size as input array.\n",
        "    \"\"\"\n",
        "    print(\"Predicting lung segmentation regions ....\")\n",
        "    model = load_seg_model(model_path)\n",
        "    pred = model.predict(resampled_image_arr, batch_size=batch_size, verbose=0).reshape(resampled_image_arr.shape[0:3])\n",
        "    pr = pred > 0.5\n",
        "\n",
        "    return pr.astype(int)\n"
      ],
      "metadata": {
        "id": "vqotPyjce3lP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After lung masks are obtained, we use that mask to crop the bounding box containing lung regions from the original CXRs."
      ],
      "metadata": {
        "id": "s6Cviy-5g4ZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _segmented_lung_2_tb_cnn(new_size, resampled_image, np_lung_segmentation_mask,\n",
        "                             original_image, gaussian_sigma):\n",
        "    \"\"\"\n",
        "    Resample a subregion of a given image based on a mask.\n",
        "    Args:\n",
        "       original_image (SimpleITK.Image): Original Image\n",
        "       resampled_image (SimpleITK.Image): Image that was resampled to create sitk_lung_segmentation_image.\n",
        "                                         Both images occupy the same physical space, but they differ in\n",
        "                                         size (pixel count) and spacing.\n",
        "       np_lung_segmentation_mask (numpy.array): Array denoting segmentation mask.\n",
        "                                                Array size matches the sitk_lung_segmentation_image\n",
        "                                                image size.\n",
        "       new_size (list like): The region in the original_image defined by the segmentation mask is resampled\n",
        "                             to this size.\n",
        "       gaussian_sigma(scalar or tuple with image dimension length): If given,\n",
        "               blur the image with a Gaussian with the given standard deviation(s)\n",
        "               before resampling.\n",
        "    Returns:\n",
        "        SimpleITK.Image and Confidence: Returns the lung segmented region in the\n",
        "                                        original image which is resampled to the\n",
        "                                        given size and returns segmentation confidence\n",
        "                                        if the segmentation process of the CXR\n",
        "                                        was done well.\n",
        "\n",
        "    \"\"\"\n",
        "    lung_labels = [1, 2]\n",
        "    segmentation_image = sitk.GetImageFromArray(np_lung_segmentation_mask)\n",
        "    segmentation_image.CopyInformation(resampled_image)\n",
        "    # relabel the segmentation so that the labels 1, and 2 correspond to the largest\n",
        "    # components, assumed to be the lungs\n",
        "    disjointed_segmentation_image = sitk.RelabelComponent(sitk.ConnectedComponent(segmentation_image),\n",
        "                                                          sortByObjectSize=True)\n",
        "    if gaussian_sigma:\n",
        "        original_image = sitk.SmoothingRecursiveGaussian(original_image, gaussian_sigma)\n",
        "    label_shape_filter = sitk.LabelShapeStatisticsImageFilter()\n",
        "    label_shape_filter.Execute(disjointed_segmentation_image)\n",
        "    # Assign segmentation confidence variable to 'High' whenever segmentation process\n",
        "    # \"succeeds\" and 'Low' whenever segmentation process fails\n",
        "    seg_confidence = 'High'\n",
        "    perimeter_threshold = 600  # For successful segmentation of lungs\n",
        "    try:\n",
        "        # Some of the images which are successfully segmented do not contain lungs\n",
        "        # in the images.So we threshold the perimeter of the 2 lung regions.Area\n",
        "        # is not taken as a measure becuase some of the successfully segmented images\n",
        "        # have a major area  difference. E.g: 'CHNCXR_0361_1.png'(Due to the existence\n",
        "        # of large airspaces in the lungs). So area is not taken as a measure for\n",
        "        # filtering out the \"non-lung\" containing images\n",
        "        perimeter_left = label_shape_filter.GetPerimeter(lung_labels[0])\n",
        "        perimeter_right = label_shape_filter.GetPerimeter(lung_labels[1])\n",
        "        if not (perimeter_left > perimeter_threshold and perimeter_right > perimeter_threshold):  # Threshold\n",
        "            np_lung_segmentation_mask = np.ones(resampled_image.GetSize(), dtype=np.int64)\n",
        "            seg_confidence = 'Low'\n",
        "    except:\n",
        "        # Some predicted masks contain no lung masks(no '1's in 'np_lung_segmentation_mask' array)\n",
        "        # Assigning lung predicted masks to all ones would essentially select all the\n",
        "        # area of the original image in the end\n",
        "        np_lung_segmentation_mask = np.ones(resampled_image.GetSize(), dtype=np.int64)\n",
        "        seg_confidence = 'Low'\n",
        "\n",
        "    # Replace all the noise objects(apart from 2 lung regions) with zeros\n",
        "    noise_labels = [x for x in label_shape_filter.GetLabels() if x not in lung_labels]\n",
        "    for ns_label in noise_labels:\n",
        "        ns_bb = label_shape_filter.GetBoundingBox(ns_label)\n",
        "        np_lung_segmentation_mask[ns_bb[1]:ns_bb[1] + ns_bb[3], ns_bb[0]:ns_bb[0] + ns_bb[2]] = np.zeros(\n",
        "            (ns_bb[3], ns_bb[2]))\n",
        "    segmentation_image = sitk.GetImageFromArray(np_lung_segmentation_mask)\n",
        "    segmentation_image.CopyInformation(resampled_image)\n",
        "    label_shape_filter = sitk.LabelShapeStatisticsImageFilter()\n",
        "    label_shape_filter.Execute(segmentation_image)\n",
        "    # The bounding box's first two entries are the starting index and last \n",
        "    # two entries the size\n",
        "    bounding_box = label_shape_filter.GetBoundingBox(lung_labels[0])\n",
        "    new_origin = segmentation_image.TransformIndexToPhysicalPoint(bounding_box[0:2])\n",
        "    new_spacing = [(sz - 1) * spc / (new_sz - 1) for sz, spc, new_sz in\n",
        "                   zip(bounding_box[2:4], segmentation_image.GetSpacing(), new_size)]\n",
        "    arr = sitk.GetArrayFromImage(sitk.Resample(original_image, new_size, sitk.Transform(), sitk.sitkLinear,\n",
        "                                               new_origin, new_spacing, original_image.GetDirection(),\n",
        "                                               0))\n",
        "    arr = (arr - np.mean(arr)) / np.std(arr)\n",
        "    return np.reshape(arr, arr.shape + (1,))"
      ],
      "metadata": {
        "id": "NoNTbW5OfD5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below snippet code can be used to generate final segmentation array containing cropped image array for all the input files"
      ],
      "metadata": {
        "id": "LkYaOpv9hVhu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _standardize_input(img):\n",
        "        arr = sitk.GetArrayFromImage(img)\n",
        "        arr = arr - np.min(arr)\n",
        "        arr = arr / np.max(arr)\n",
        "        arr = exposure.equalize_adapthist(arr) \n",
        "        return arr\n",
        "        \n",
        "def _gen_seg_image_arr(files,model_path,model_input_size,batch_size,required_output_img_size,gaussian_sigma):\n",
        "    '''\n",
        "    Generate an array from lung segmented images.This process happens in 3 stages:\n",
        "    1.) Reading and Resampling of original images\n",
        "    2.) Predict masks from the array of resampled image array\n",
        "    3.) Segment lungs from the original images using the predicted masks \n",
        "    \n",
        "    Args:\n",
        "        files(list):  List of CXR filepaths\n",
        "        model_path(string): path for trained model.\n",
        "        model_input_size(tuple): size required as model input\n",
        "        batch_size(int): batch size for segmentation algorithm to predict\n",
        "        required_output_img_size: required output image size for building tb/not-tb model\n",
        "        gaussian_sigma(scalar or tuple with image dimension length): If given, \n",
        "               blur the image with a Gaussian with the given standard deviation(s)\n",
        "               before resampling.\n",
        "    Returns:\n",
        "        list of numpy array,list of labels,list of patients: array extracted from segmented images,\n",
        "                                                             labels and patientIDs\n",
        "        '''   \n",
        "\n",
        "    resampled_imgs = np.ndarray((len(files),),dtype=np.object)\n",
        "    original_imgs = np.ndarray((len(files),),dtype=np.object)\n",
        "\n",
        "    #Read and resample original images to segmentation algo. size \n",
        "\n",
        "    returned_imgs = [_resample_cxr_for_lung_segmentation_cnn(model_input_size, gaussian_sigma,file) for file in files]\n",
        "\n",
        "    print(\"Resampling of all images done\")      \n",
        "\n",
        "    original_imgs, resampled_imgs= zip(*returned_imgs)               \n",
        "    #Extract array from each resampled image\n",
        "    resampled_img_arr = np.asarray(list(map(lambda img:_standardize_input(img), resampled_imgs)))   \n",
        "\n",
        "    #Reshape the array to fit into model input size\n",
        "    resampled_img_arr = np.reshape(resampled_img_arr,resampled_img_arr.shape+(1,)) \n",
        "    resampled_img_arr = np.stack((resampled_img_arr, resampled_img_arr, resampled_img_arr), axis=3)\n",
        "\n",
        "    #Predict Images\n",
        "    pred_masks = _predict_mask(resampled_img_arr,model_path,batch_size)\n",
        "\n",
        "    print(\"Segmentation of lungs in CXRs done..\")\n",
        "    #Segment Lungs from Original Images\n",
        "    func = partial(_segmented_lung_2_tb_cnn,required_output_img_size)\n",
        "\n",
        "    final_images_list = []\n",
        "    i = 0\n",
        "    for r,p,o in zip(resampled_imgs,pred_masks, original_imgs):\n",
        "        print(\"Cropping lung regions in \"+ files[i])\n",
        "        final_images_list.append(func(r, p, o, gaussian_sigma))\n",
        "        i = i+1\n",
        "\n",
        "    print(\"Cropping done.\")\n",
        "       \n",
        "    return final_images_list"
      ],
      "metadata": {
        "id": "7gMXCbqefMH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Divide training and validation"
      ],
      "metadata": {
        "id": "zPsXccEQeKvW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_tb_samples = sum(shenzen_labels)\n",
        "num_not_tb_samples = len(shenzen_labels) - num_tb_samples\n",
        "print(\"TB samples :\" + str(num_tb_samples) + \", NOT-TB samples:\"+str( num_not_tb_samples)) #336,326\n",
        "\n",
        "# Select random 326 tb images to balance the dataset\n",
        "np.random.seed(42)\n",
        "balanced_tb_samples_idxs = np.random.choice(num_tb_samples,num_not_tb_samples,replace=False)\n",
        "balanced_tb_samples = [shenzen_tb_cxrs[idx] for idx in balanced_tb_samples_idxs]\n",
        "\n",
        "combined_balanced_samples = balanced_tb_samples + shenzen_not_tb_cxrs \n",
        "combined_balanced_labels = np.asarray([1]*len(balanced_tb_samples)+[0]*len(shenzen_not_tb_cxrs))\n",
        "print(\"Combined balanced samples :\"+str(len(combined_balanced_samples)))\n",
        "\n",
        "X_train_val_indices, X_test_indices, y_train_val, y_test = train_test_split(range(len(combined_balanced_samples)), combined_balanced_labels, test_size=0.2, random_state=42,stratify=combined_balanced_labels)\n",
        "X_train_indices, X_val_indices, y_train, y_val = train_test_split(X_train_val_indices, y_train_val, test_size=0.2, random_state=4,stratify=y_train_val)\n",
        "\n",
        "#Train-64%, Val-16%, Test-20%\n",
        "print(\"Train samples :\"+str(len(X_train_indices)) + \", Val samples :\"+str(len(X_val_indices)) + \", Test samples :\" +str(len(X_test_indices)))"
      ],
      "metadata": {
        "id": "J785pnYTB4dU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Until the above step, we defined all the preprocessing functions for preprocessing and segregated training and validation sets. We will now execute the function which will accept the files that we use for classification analysis, predicts lung regions on them and crops those regions \"only\" to contain bounding box area of lungs."
      ],
      "metadata": {
        "id": "eBLidGEaGlc4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lung_segment_model_path = os.path.join(root_dir,'lung_segment_model.h5')\n",
        "lung_segment_model_input_size=(256,256)\n",
        "batch_size=8\n",
        "required_output_img_size=(224,224)\n",
        "gaussian_sigma=0.5\n",
        "\n",
        "data_bounding_box_lung_list = _gen_seg_image_arr(combined_balanced_samples,lung_segment_model_path,lung_segment_model_input_size,batch_size,required_output_img_size,gaussian_sigma)\n"
      ],
      "metadata": {
        "id": "3GtsAWxfGDrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zls4e94Tl1gi"
      },
      "source": [
        "### Display cropped images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LvRHNGdEl1gi"
      },
      "outputs": [],
      "source": [
        "plt.rcParams[\"figure.figsize\"]=8,8\n",
        "fig_rows = 3\n",
        "fig_columns = 5\n",
        "_,subfigs = plt.subplots(fig_rows, fig_columns)\n",
        "k = 0\n",
        "for row in range(fig_rows):\n",
        "  for column in range(fig_columns):     \n",
        "      arr = data_bounding_box_lung_list[k][:,:,0]\n",
        "      arr = arr - np.min(arr)\n",
        "      arr = arr / np.max(arr)\n",
        "      arr = arr*255\n",
        "      arr = arr.astype(int)\n",
        "      subfigs[row,column].imshow(arr, cmap = 'gray')\n",
        "      subfigs[row,column].set_title('#'+str(k))\n",
        "      subfigs[row,column].axis('off')\n",
        "      k = k+1\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Prepare input for training TB vs NOT-TB model"
      ],
      "metadata": {
        "id": "QIuxEeml7h5p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_bounding_box_lung_arr = np.asarray([data_bounding_box_lung_list[idx] for idx in X_train_indices])\n",
        "val_bounding_box_lung_arr = np.asarray([data_bounding_box_lung_list[idx] for idx in X_val_indices])\n",
        "test_bounding_box_lung_arr = np.asarray([data_bounding_box_lung_list[idx] for idx in X_test_indices])\n",
        "\n",
        "train_bounding_box_lung_arr = np.repeat(train_bounding_box_lung_arr,repeats=3,axis=3)\n",
        "val_bounding_box_lung_arr = np.repeat(val_bounding_box_lung_arr,repeats=3,axis=3)\n",
        "test_bounding_box_lung_arr = np.repeat(test_bounding_box_lung_arr,repeats=3,axis=3)\n",
        "\n",
        "print(train_bounding_box_lung_arr.shape)\n",
        "print(val_bounding_box_lung_arr.shape)\n",
        "print(test_bounding_box_lung_arr.shape)\n",
        "\n",
        "np.savez(os.path.join(root_dir,'shenzen_train_data.npz'),train_bounding_box_lung_arr,y_train)\n",
        "np.savez(os.path.join(root_dir,'shenzen_val_data.npz'),val_bounding_box_lung_arr,y_val)\n",
        "np.savez(os.path.join(root_dir,'shenzen_test_data.npz'),test_bounding_box_lung_arr,y_test)      "
      ],
      "metadata": {
        "id": "rb74AHuv8EXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shenzen_train = np.load(os.path.join(root_dir,'shenzen_train_data.npz'))\n",
        "shenzen_val = np.load(os.path.join(root_dir,'shenzen_val_data.npz'))\n",
        "shenzen_test = np.load(os.path.join(root_dir,'shenzen_test_data.npz'))\n",
        "\n",
        "train_bounding_box_lung_arr,y_train = shenzen_train['arr_0'],shenzen_train['arr_1']\n",
        "val_bounding_box_lung_arr,y_val = shenzen_val['arr_0'],shenzen_val['arr_1']\n",
        "test_bounding_box_lung_arr,y_test = shenzen_test['arr_0'],shenzen_test['arr_1']\n",
        "\n"
      ],
      "metadata": {
        "id": "9m9RGuBTjgFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSXQ0FBwl1gi"
      },
      "source": [
        "### Use tf.keras for training and validation\n",
        "\n",
        "On Colab run the following %tensorflow_version line magic function to set tensorflow to v2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Fr6NZz7l1gi"
      },
      "outputs": [],
      "source": [
        "%tensorflow_version 2.x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YnihRNjXl1gj"
      },
      "outputs": [],
      "source": [
        "print(tf.__version__)\n",
        "tf.keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare Training settings"
      ],
      "metadata": {
        "id": "MYwKJVLK1Lwb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EfVTcPxml1gj"
      },
      "outputs": [],
      "source": [
        "# Define model parameters \n",
        "img_width = 224\n",
        "img_height = 224\n",
        "epochs = 100\n",
        "batch_size=8"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### User can choose any pretrained model(DenseNet121, VGG16 etc.) or custom model to start their training with. We choose DenseNet121 because it is a lightweight architecture which works well with small datasets."
      ],
      "metadata": {
        "id": "Xw_Y3yXs1T2E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2U714uS6l1gj"
      },
      "outputs": [],
      "source": [
        "base_model = tf.keras.applications.DenseNet121(weights='imagenet', include_top=False, \n",
        "                                             input_shape=(img_width, img_height, 3))\n",
        "\n",
        "output = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
        "output = tf.keras.layers.Dense(1, activation='sigmoid')(output)\n",
        "\n",
        "model = tf.keras.Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train the model"
      ],
      "metadata": {
        "id": "nc0e8hc-10_l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J7RNocekl1gk"
      },
      "outputs": [],
      "source": [
        "# Callbacks to stop early and save model periodically\n",
        "model_output_filename = os.path.join(root_dir,'best_tb_not_tb_model.h5')\n",
        "earlystopper = EarlyStopping(monitor='val_loss', patience=30, verbose=1, restore_best_weights=True)\n",
        "modelSaver = ModelCheckpoint(model_output_filename, monitor='val_loss', verbose=0,\n",
        "                              save_best_only=True,\n",
        "                              save_weights_only=False, mode='auto', save_freq='epoch')\n",
        "\n",
        "# set optimization params and compile\n",
        "opt = optimizers.Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer=opt, loss='binary_crossentropy', metrics='accuracy')\n",
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    featurewise_center=True,\n",
        "    featurewise_std_normalization=True,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "# compute quantities required for featurewise normalization\n",
        "# (std, mean, and principal components if ZCA whitening is applied)\n",
        "datagen.fit(train_bounding_box_lung_arr)\n",
        "# fits the model on batches with real-time data augmentation:\n",
        "model.fit_generator(datagen.flow(train_bounding_box_lung_arr, y_train, batch_size=batch_size), \n",
        "                    epochs=epochs, # one forward/backward pass of training data\n",
        "                    steps_per_epoch=train_bounding_box_lung_arr.shape[0]//batch_size, # number of images comprising of one epoch\n",
        "                    validation_data=(val_bounding_box_lung_arr, y_val), # data for validation\n",
        "                    callbacks=[earlystopper,modelSaver])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test the model"
      ],
      "metadata": {
        "id": "DiErESvPrFsX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JasTXLQdl1gm"
      },
      "outputs": [],
      "source": [
        "model_output_filename = os.path.join(root_dir,'best_tb_not_tb_model.h5')\n",
        "model = tf.keras.models.load_model(model_output_filename)\n",
        "y_pred = model.predict(test_bounding_box_lung_arr)  \n",
        "y_pred = np.squeeze(y_pred)\n",
        "\n",
        "# User can change the threshold\n",
        "threshold=0.5\n",
        "y_pred =  y_pred > threshold \n",
        "# performance metric calculation\n",
        "recall = metrics.recall_score(y_test, y_pred)\n",
        "precision = metrics.precision_score(y_test, y_pred)\n",
        "f1 = metrics.f1_score(y_test, y_pred)\n",
        "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
        "print(metrics.confusion_matrix(y_test, y_pred))\n",
        "cl_report = metrics.classification_report(y_test, y_pred)\n",
        "roc_auc = metrics.roc_auc_score(y_test, y_pred)\n",
        "\n",
        "precision, recall, thresholds = metrics.precision_recall_curve( y_test, y_pred)\n",
        "precision_recall_auc = metrics.auc(recall,precision )\n",
        "# print to screen\n",
        "print(\"Recall: \" + str(recall))\n",
        "print(\"Precision: \" + str(precision))\n",
        "print('F1 Score: ' + str(f1))\n",
        "print(\"Accuracy: \" + str(accuracy))\n",
        "print(\"ROC AUC :\" + str(roc_auc))    \n",
        "print(\"Precision Recall AUC: \" + str(precision_recall_auc))                                       "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After evaluating the model on test set, consider Montgomery county dataset as another test set and test your model on that to verify how \"generalizable\" your model is. To prepare the test set for Shenzen dataset, one can follow the same preprocessing steps as discussed above."
      ],
      "metadata": {
        "id": "ZjhlNoFU0OwP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mont_cxrs = glob.glob(os.path.join(root_dir,'MontgomerySet','CXR_png','*.png'))\n",
        "mont_tb_cxrs = glob.glob(os.path.join(root_dir,'MontgomerySet','CXR_png','*_1.png'))\n",
        "mont_not_tb_cxrs = glob.glob(os.path.join(root_dir,'MontgomerySet','CXR_png','*_0.png'))\n",
        "mont_labels = [int(os.path.splitext(cxr_file)[0].split('_')[-1]) for cxr_file in mont_cxrs]"
      ],
      "metadata": {
        "id": "jzJuj4y2PdAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate cropped lung data for Montgomery County CXRs"
      ],
      "metadata": {
        "id": "1cbGlbLIVpDk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "montgomery_county_data_bounding_box_lung_list = _gen_seg_image_arr(mont_cxrs,lung_segment_model_path,lung_segment_model_input_size,batch_size,required_output_img_size,gaussian_sigma)\n"
      ],
      "metadata": {
        "id": "0YeRI4sTVm4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "montgomery_county_data_bounding_box_lung_arr = np.asarray(montgomery_county_data_bounding_box_lung_list)\n",
        "\n",
        "montgomery_county_data_bounding_box_lung_arr = np.repeat(montgomery_county_data_bounding_box_lung_arr,repeats=3,axis=3) \n",
        "\n",
        "np.savez(os.path.join(root_dir,'cropped_mont_data.npz'),montgomery_county_data_bounding_box_lung_arr,mont_labels)"
      ],
      "metadata": {
        "id": "BzY6i-qEfLni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predict on Montgomery County dataset using the trained model on Shenzen dataset to check for generalization"
      ],
      "metadata": {
        "id": "YEOyIF6Mouen"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_output_filename = os.path.join(root_dir,'best_tb_not_tb_model.h5')\n",
        "model = tf.keras.models.load_model(model_output_filename)\n",
        "mont_y_pred = model.predict(montgomery_county_data_bounding_box_lung_arr)  \n",
        "mont_y_pred = np.squeeze(mont_y_pred)\n"
      ],
      "metadata": {
        "id": "Cwz4OK05oe6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###We calculate AUC under precision recall curve as the classes between TB and NOT-TB are imbalanced in Montgomery County dataset"
      ],
      "metadata": {
        "id": "LNyDdYUejzBO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "precision, recall, _ = metrics.precision_recall_curve(mont_labels, mont_y_pred)\n",
        "\n",
        "precision_recall_auc_on_mont = metrics.auc(recall, precision)\n",
        "\n",
        "print(\"Precision Recall AUC on Montgomery County dataset: \" + str(precision_recall_auc_on_mont)) "
      ],
      "metadata": {
        "id": "IrnHM6oJirMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above AUC value, we can see that the trained model has not generalized well. I would encourage each one of you to try different pretrained network architectures with various layers and various hyperparameters and see if you can increase not only the performance of test data  (AUC of precision - recall curve)  but also the performance on the Montgomery County dataset as well."
      ],
      "metadata": {
        "id": "k5yXJr4F_r9T"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "tb_not_tb_classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}